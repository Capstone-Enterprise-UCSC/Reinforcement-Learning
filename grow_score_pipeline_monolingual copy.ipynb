{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "peDC8aJtRP9-",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from datasets) (1.24.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from datasets) (14.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from datasets) (2.28.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
            "Requirement already satisfied: aiohttp in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from datasets) (3.9.1)\n",
            "Collecting huggingface-hub>=0.18.0 (from datasets)\n",
            "  Using cached huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: packaging in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: filelock in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface-hub>=0.18.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface-hub>=0.18.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Using cached huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "Installing collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.16.4\n",
            "    Uninstalling huggingface-hub-0.16.4:\n",
            "      Successfully uninstalled huggingface-hub-0.16.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "unbabel-comet 2.2.0 requires huggingface-hub<0.17.0,>=0.16.0, but you have huggingface-hub 0.19.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.19.4\n",
            "Requirement already satisfied: transformers in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from transformers) (1.24.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from transformers) (2023.10.3)\n",
            "Requirement already satisfied: requests in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests->transformers) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests->transformers) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: sentencepiece in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (0.1.99)\n",
            "Requirement already satisfied: huggingface_hub in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (0.19.4)\n",
            "Requirement already satisfied: filelock in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface_hub) (3.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface_hub) (2023.10.0)\n",
            "Requirement already satisfied: requests in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface_hub) (2.28.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface_hub) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface_hub) (4.4.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests->huggingface_hub) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests->huggingface_hub) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests->huggingface_hub) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install -U huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (3.8.1)\n",
            "Requirement already satisfied: click in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from nltk) (2023.10.3)\n",
            "Requirement already satisfied: tqdm in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: unbabel-comet in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (2.2.0)\n",
            "Requirement already satisfied: entmax<2.0,>=1.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from unbabel-comet) (1.1)\n",
            "Collecting huggingface-hub<0.17.0,>=0.16.0 (from unbabel-comet)\n",
            "  Using cached huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: jsonargparse==3.13.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from unbabel-comet) (3.13.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from unbabel-comet) (1.24.1)\n",
            "Requirement already satisfied: pandas>=1.4.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from unbabel-comet) (2.0.3)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.24.4 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from unbabel-comet) (4.25.1)\n",
            "Requirement already satisfied: pytorch-lightning<3.0.0,>=2.0.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from unbabel-comet) (2.1.2)\n",
            "Requirement already satisfied: sacrebleu<3.0.0,>=2.0.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from unbabel-comet) (2.3.3)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from unbabel-comet) (1.10.1)\n",
            "Requirement already satisfied: sentencepiece<0.2.0,>=0.1.96 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from unbabel-comet) (0.1.99)\n",
            "Requirement already satisfied: torch>=1.6.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from unbabel-comet) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchmetrics<0.11.0,>=0.10.2 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from unbabel-comet) (0.10.3)\n",
            "Requirement already satisfied: transformers<5.0,>=4.17 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from unbabel-comet) (4.35.2)\n",
            "Requirement already satisfied: PyYAML>=3.13 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from jsonargparse==3.13.1->unbabel-comet) (6.0.1)\n",
            "Requirement already satisfied: filelock in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface-hub<0.17.0,>=0.16.0->unbabel-comet) (3.9.0)\n",
            "Requirement already satisfied: fsspec in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface-hub<0.17.0,>=0.16.0->unbabel-comet) (2023.10.0)\n",
            "Requirement already satisfied: requests in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface-hub<0.17.0,>=0.16.0->unbabel-comet) (2.28.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface-hub<0.17.0,>=0.16.0->unbabel-comet) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface-hub<0.17.0,>=0.16.0->unbabel-comet) (4.4.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface-hub<0.17.0,>=0.16.0->unbabel-comet) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from pandas>=1.4.1->unbabel-comet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from pandas>=1.4.1->unbabel-comet) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from pandas>=1.4.1->unbabel-comet) (2023.3)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (0.10.0)\n",
            "Requirement already satisfied: portalocker in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (2.8.2)\n",
            "Requirement already satisfied: regex in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (2023.10.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.9.0)\n",
            "Requirement already satisfied: colorama in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (0.4.6)\n",
            "Requirement already satisfied: lxml in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet) (4.9.3)\n",
            "Requirement already satisfied: sympy in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from torch>=1.6.0->unbabel-comet) (1.12)\n",
            "Requirement already satisfied: networkx in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from torch>=1.6.0->unbabel-comet) (3.0)\n",
            "Requirement already satisfied: jinja2 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from torch>=1.6.0->unbabel-comet) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from torch>=1.6.0->unbabel-comet) (2.1.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from transformers<5.0,>=4.17->unbabel-comet) (0.4.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (3.9.1)\n",
            "Requirement already satisfied: setuptools in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (68.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.1->unbabel-comet) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from jinja2->torch>=1.6.0->unbabel-comet) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests->huggingface-hub<0.17.0,>=0.16.0->unbabel-comet) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests->huggingface-hub<0.17.0,>=0.16.0->unbabel-comet) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests->huggingface-hub<0.17.0,>=0.16.0->unbabel-comet) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from requests->huggingface-hub<0.17.0,>=0.16.0->unbabel-comet) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from sympy->torch>=1.6.0->unbabel-comet) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (4.0.3)\n",
            "Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "Installing collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 2.15.0 requires huggingface-hub>=0.18.0, but you have huggingface-hub 0.16.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.16.4\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install unbabel-comet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip3 install git+https://github.com/Unbabel/COMET.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ncb3UKLeRuAM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Softmax\n",
        "\n",
        "from typing import List, Optional, Tuple, Union, Dict, Any\n",
        "\n",
        "from datasets import load_dataset, Dataset, DatasetDict, load_metric, load_from_disk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, EarlyStoppingCallback\n",
        "from transformers import PreTrainedModel, TrainingArguments\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7X174k9iA6vp"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "_numpy_rng = np.random.default_rng(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.use_deterministic_algorithms(False)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JT4ECKP2A5xu"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMJd5N7nRP-A"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0XB_7VxgRP-B"
      },
      "outputs": [],
      "source": [
        "model_name = 'm2m100_418M'\n",
        "experiment = 'grow-1-monolingual-ha-en'\n",
        "dataset_hub_name = 'Parikshith/monolingual-ha'\n",
        "translated_data_hub_name = 'grow-1-monolingual-ha-en'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dnQUcF1JRP-C"
      },
      "outputs": [],
      "source": [
        "# model = M2M100ForConditionalGeneration.from_pretrained(f\"facebook/{model_name}\")\n",
        "model = M2M100ForConditionalGeneration.from_pretrained(\"Parikshith/ha-en-finetune-og\")\n",
        "model = model.to(device)\n",
        "tokenizer = M2M100Tokenizer.from_pretrained(f\"facebook/{model_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0XWA1AcRP-C"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cMdgNXOXRP-D"
      },
      "outputs": [],
      "source": [
        "src_lang = 'ha'\n",
        "tgt_lang = 'en'\n",
        "tokenizer.src_lang = \"ha\"\n",
        "tokenizer.tgt_lang = \"en\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "X0-QUt3FRP-D"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading readme: 100%|██████████| 520/520 [00:00<00:00, 277kB/s]\n",
            "Downloading data: 100%|██████████| 277M/277M [00:22<00:00, 12.2MB/s]\n",
            "Downloading data: 100%|██████████| 8.23M/8.23M [00:00<00:00, 19.7MB/s]\n",
            "Downloading data: 100%|██████████| 82.2M/82.2M [00:06<00:00, 13.1MB/s]\n",
            "Downloading data files: 100%|██████████| 3/3 [00:29<00:00,  9.83s/it]\n",
            "Extracting data files: 100%|██████████| 3/3 [00:00<00:00, 689.78it/s]\n",
            "Generating complete split: 100%|██████████| 3372487/3372487 [00:01<00:00, 1691470.59 examples/s]\n",
            "Generating small split: 100%|██████████| 100000/100000 [00:00<00:00, 2214930.95 examples/s]\n",
            "Generating one_million split: 100%|██████████| 1000000/1000000 [00:00<00:00, 2263986.28 examples/s]\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(dataset_hub_name, split=\"one_million\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "first_100K = dataset.select(range(100000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYM6TuG9RP-F"
      },
      "source": [
        "# Grow Step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "H6uKTCiQRP-H"
      },
      "outputs": [],
      "source": [
        "def generate_text_and_add_to_dataset(dataset, model, tokenizer):\n",
        "    # Define a function to generate text using the model\n",
        "    def generate_text(prompt):\n",
        "        input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=256).input_ids.to(device)\n",
        "        with torch.no_grad():\n",
        "          output_ids = model.generate(input_ids, forced_bos_token_id=tokenizer.get_lang_id(\"en\"))\n",
        "          generated_text = [tokenizer.decode(output, skip_special_tokens=True) for output in output_ids]\n",
        "        return generated_text\n",
        "\n",
        "    # Add a new field to the dataset with generated text\n",
        "    def add_generated_text(example):\n",
        "      example[\"generated_text\"] = generate_text(example[\"ha\"])\n",
        "      return example\n",
        "\n",
        "    # Apply the function to each example in the dataset\n",
        "    dataset = dataset.map(add_generated_text)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360,
          "referenced_widgets": [
            "c8d327f2e7174e6285aab03f377c18d1",
            "f41d2b0fd48a4245a3506f5e563c8557",
            "b8eac47a8e9c420f98e5153363358811",
            "104e8ad54b494fc482eab1082e562a89",
            "0170c568500a4c608ac2492badf05ebc",
            "d564d8a164514e85a0760cf13213b14f",
            "253ea4c26ac7476e8dbb9c67d27397da",
            "c30f2ec9fc284c9ebb8b23dc92399d7f",
            "7c0d49919cd04125989a1ab2db7a5940",
            "ba091bbe608c40a8a25ee2b5198e5c52",
            "beea97e17653494da4307def19f74251"
          ]
        },
        "id": "fItPjv9zlNnQ",
        "outputId": "d85740ef-0452-48dc-e592-ed4f3e6225b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 100000/100000 [14:27:21<00:00,  1.92 examples/s]  \n"
          ]
        }
      ],
      "source": [
        "translated_dataset = generate_text_and_add_to_dataset(first_100K, model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4p9vLMvPrqzd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['ha', 'generated_text'],\n",
              "    num_rows: 100000\n",
              "})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translated_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving the dataset (1/1 shards): 100%|██████████| 100000/100000 [00:00<00:00, 2080002.38 examples/s]\n"
          ]
        }
      ],
      "source": [
        "translated_dataset.save_to_disk('/home/phonnego/lrl_capstone/Reinforcement-Learning/new_monolingual_generations/first_100k')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 100000/100000 [00:05<00:00, 19189.40 examples/s]\n"
          ]
        }
      ],
      "source": [
        "translated_dataset_1 = translated_dataset.map(lambda example: {'generated_text': example['generated_text'][0] if isinstance(example['generated_text'], list) else example['generated_text']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ha': 'Babu shakka, Kevin Federline ya kasance dan wasan rawa a shirin Timberlake.',\n",
              " 'generated_text': ['There is no doubt that Kevin Federline played a role in the Timberlake program.']}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translated_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ha': 'Babu shakka, Kevin Federline ya kasance dan wasan rawa a shirin Timberlake.',\n",
              " 'generated_text': 'There is no doubt that Kevin Federline played a role in the Timberlake program.'}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translated_dataset_1[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving the dataset (1/1 shards): 100%|██████████| 100000/100000 [00:00<00:00, 1235836.06 examples/s]\n"
          ]
        }
      ],
      "source": [
        "translated_dataset_1.save_to_disk('/home/phonnego/lrl_capstone/Reinforcement-Learning/new_monolingual_generations_1/first_100k')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "obSOF-vMDXU-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating parquet from Arrow format: 100%|██████████| 100/100 [00:00<00:00, 371.69ba/s]\n",
            "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.64s/it]\n"
          ]
        }
      ],
      "source": [
        "translated_dataset.push_to_hub(translated_data_hub_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "translated_dataset = translated_dataset.map(lambda example: {'generated_text': example['generated_text'][0] if isinstance(example['generated_text'], list) else example['generated_text']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating parquet from Arrow format: 100%|██████████| 100/100 [00:00<00:00, 343.26ba/s]\n",
            "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n"
          ]
        }
      ],
      "source": [
        "translated_dataset.push_to_hub(translated_data_hub_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 25827.00it/s]\n",
            "Lightning automatically upgraded your loaded checkpoint from v1.3.5 to v2.1.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/huggingface/hub/models--Unbabel--wmt20-comet-qe-da/snapshots/2e7ffc84fb67d99cf92506611766463bb9230cfb/checkpoints/model.ckpt`\n",
            "Encoder model frozen.\n",
            "/home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages/pytorch_lightning/core/saving.py:177: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
          ]
        }
      ],
      "source": [
        "from comet import download_model, load_from_checkpoint\n",
        "\n",
        "model_path = download_model(\"Unbabel/wmt20-comet-qe-da\")\n",
        "model = load_from_checkpoint(model_path)\n",
        "\n",
        "def score_samples(dataset):\n",
        "  dataset = dataset.rename_column(\"ha\", \"src\")\n",
        "  dataset = dataset.rename_column(\"generated_text\", \"mt\")\n",
        "  model_output = model.predict(dataset, batch_size=8, gpus=1)\n",
        "  dataset = dataset.add_column(\"score\", model_output['scores'])\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_name = 'Parikshith/grow-1-monolingual-ha-en'\n",
        "dataset_ = load_dataset(dataset_name, split=\"small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5]\n",
            "Predicting DataLoader 0: 100%|██████████| 12500/12500 [10:26<00:00, 19.95it/s]\n"
          ]
        }
      ],
      "source": [
        "translated_dataset_scored = score_samples(dataset_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['src', 'mt', 'score'],\n",
              "    num_rows: 100000\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translated_dataset_scored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating parquet from Arrow format: 100%|██████████| 100/100 [00:00<00:00, 344.87ba/s]\n",
            "Uploading the dataset shards: 100%|██████████| 1/1 [00:03<00:00,  3.09s/it]\n"
          ]
        }
      ],
      "source": [
        "translated_data_hub = 'grow-1-monolingual-ha-en-comet'\n",
        "translated_dataset_scored.push_to_hub(translated_data_hub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Lightning automatically upgraded your loaded checkpoint from v1.3.5 to v2.1.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint comet/wmt21-comet-qe-da/checkpoints/model.ckpt`\n",
            "Encoder model frozen.\n",
            "/home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages/pytorch_lightning/core/saving.py:177: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
          ]
        }
      ],
      "source": [
        "from comet import download_model, load_from_checkpoint\n",
        "\n",
        "# model_path = download_model(\"Unbabel/wmt20-comet-qe-da\")\n",
        "model = load_from_checkpoint('/home/phonnego/lrl_capstone/Reinforcement-Learning/comet/wmt21-comet-qe-da/checkpoints/model.ckpt')\n",
        "\n",
        "def score_samples(dataset):\n",
        "  dataset = dataset.rename_column(\"ha\", \"src\")\n",
        "  dataset = dataset.rename_column(\"generated_text\", \"mt\")\n",
        "  model_output = model.predict(dataset, batch_size=8, gpus=1)\n",
        "  dataset = dataset.add_column(\"score\", model_output['scores'])\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5]\n",
            "Predicting DataLoader 0:   3%|▎         | 324/12500 [00:15<09:52, 20.55it/s]"
          ]
        }
      ],
      "source": [
        "translated_dataset_scored = score_samples(dataset_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0170c568500a4c608ac2492badf05ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "104e8ad54b494fc482eab1082e562a89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba091bbe608c40a8a25ee2b5198e5c52",
            "placeholder": "​",
            "style": "IPY_MODEL_beea97e17653494da4307def19f74251",
            "value": " 41/100000 [00:36&lt;21:00:47,  1.32 examples/s]"
          }
        },
        "253ea4c26ac7476e8dbb9c67d27397da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c0d49919cd04125989a1ab2db7a5940": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8eac47a8e9c420f98e5153363358811": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c30f2ec9fc284c9ebb8b23dc92399d7f",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c0d49919cd04125989a1ab2db7a5940",
            "value": 41
          }
        },
        "ba091bbe608c40a8a25ee2b5198e5c52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beea97e17653494da4307def19f74251": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c30f2ec9fc284c9ebb8b23dc92399d7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8d327f2e7174e6285aab03f377c18d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f41d2b0fd48a4245a3506f5e563c8557",
              "IPY_MODEL_b8eac47a8e9c420f98e5153363358811",
              "IPY_MODEL_104e8ad54b494fc482eab1082e562a89"
            ],
            "layout": "IPY_MODEL_0170c568500a4c608ac2492badf05ebc"
          }
        },
        "d564d8a164514e85a0760cf13213b14f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f41d2b0fd48a4245a3506f5e563c8557": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d564d8a164514e85a0760cf13213b14f",
            "placeholder": "​",
            "style": "IPY_MODEL_253ea4c26ac7476e8dbb9c67d27397da",
            "value": "Map:   0%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
