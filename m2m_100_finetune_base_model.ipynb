{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e1572d-e876-433f-a076-07e0e138f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"adapter-transformers@git+https://github.com/akufeldt/adapter-transformers.git@debug#egg=adapter-transformers&subdirectory=adapter-transformers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3551c529-fcb2-458d-8e5c-4544876eba0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Softmax\n",
    "\n",
    "from typing import List, Optional, Tuple, Union, Dict, Any\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict, load_metric, load_from_disk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, EarlyStoppingCallback\n",
    "from transformers import PreTrainedModel, TrainingArguments, Trainer\n",
    "from transformers.adapters import AdapterTrainer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a7310e-77b6-4eb1-87ac-9e6afd4bcbb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef787507-63c0-45ca-ba66-d56f4141dc14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "_numpy_rng = np.random.default_rng(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1631e252-26e7-4ec8-ac5b-efdd94a678fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7895b82a-ddd2-481b-8932-0907b73462a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ea527",
   "metadata": {},
   "source": [
    "# Load in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d93d087-e26d-4036-be92-8fe797856c14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'm2m100_418M'\n",
    "experiment = 'en-ha_finetune_base_model-1'\n",
    "dataset_name = 'data/en-ha'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dcb15db-3e10-4c2d-a788-9f3d755fa5f2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = M2M100ForConditionalGeneration.from_pretrained(f\"facebook/{model_name}\")\n",
    "# model = torch.nn.DataParallel(model, device_ids=[2, 3, 4])\n",
    "model = model.to(device)\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(f\"facebook/{model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da91567",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5f8621a-91a7-430f-abb8-b24099ba7ee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_lang = 'en'\n",
    "tgt_lang = 'ha'\n",
    "tokenizer.src_lang = \"en\"\n",
    "tokenizer.tgt_lang = \"ha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47843c49-de6f-4f0e-b972-33aea21d6312",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({'train':Dataset.from_pandas(pd.read_csv(f'{dataset_name}/cleaned_train.csv')).shuffle(seed=seed),\n",
    "                        'validation':Dataset.from_pandas(pd.read_csv(f'{dataset_name}/cleaned_dev.csv')).shuffle(seed=seed),\n",
    "                        'test':Dataset.from_pandas(pd.read_csv(f'{dataset_name}/test.csv')).shuffle(seed=seed),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19bbf50e-4404-4b78-ade7-3093930a1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test'] = dataset['test'].rename_column('sentence_eng_Latn','en')\n",
    "dataset['test'] = dataset['test'].rename_column('sentence_hau_Latn','ha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fab027a2-400a-4961-90b4-da9b28449308",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'ha'],\n",
       "        num_rows: 9818\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['en', 'ha'],\n",
       "        num_rows: 1113\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'ha'],\n",
       "        num_rows: 1012\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e09ae18-7223-405e-a273-4b6b39725f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [example for example in examples[src_lang]]\n",
    "    targets = [example for example in examples[tgt_lang]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=256, truncation=True, padding=\"max_length\")\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9b0dc3d-64be-41f0-8527-17fcbb3cc657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba80caf156744a129b413cc8655ec070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d8d0dd4a444f59b081342fae5d6cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd3692bd2ad49b4aa0c04646ba71bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=dataset.column_names['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eee83e5f-9065-43f5-bc23-624fa8635ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9818\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1113\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1012\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0a643",
   "metadata": {},
   "source": [
    "# Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8ad4b70-d1f7-4407-b135-9ee631f83f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sacrebleu = evaluate.load(\"sacrebleu\")\n",
    "wer = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7816c388-e691-4c08-874f-14fc97dac435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    labels = eval_preds.label_ids\n",
    "    pred_ids = eval_preds.predictions\n",
    "    if isinstance(pred_ids, tuple):\n",
    "        pred_ids = pred_ids[0]\n",
    "    \n",
    "    preds = np.argmax(pred_ids, axis=-1)\n",
    "\n",
    "    # removeme\n",
    "    #import warnings\n",
    "    #warnings.warn(f\"unprocessed preds: {preds[0]}\\n)\")\n",
    "    \n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True) \n",
    "\n",
    "    # removeme\n",
    "    #warnings.warn(f\"unprocessed decoded labels: {tokenizer.batch_decode(labels)[0]}\\n)\")\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    \n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    # remove me\n",
    "    #inputs = eval_preds.input_ids\n",
    "    #decoded_inputs = tokenizer.batch_decode(inputs)\n",
    "    \n",
    "    # Removeme\n",
    "    import warnings\n",
    "    warnings.warn(f\"preds: {decoded_preds[0]}\\n)\")\n",
    "    warnings.warn(f\"labels: {decoded_labels[0]}\\n)\")\n",
    "\n",
    "    bleu_result = sacrebleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    metrics = {\"bleu\": bleu_result[\"score\"]}\n",
    "\n",
    "    flattened_decoded_labels = [' '.join([str(x) for x in l]) for l in decoded_labels]\n",
    "    wer_score = wer.compute(predictions=decoded_preds, references=flattened_decoded_labels)\n",
    "    metrics[\"wer\"] = wer_score\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    metrics[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    metrics = {k: round(v, 4) for k, v in metrics.items()}\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c1dc421-b458-4edd-94de-c6b18fdffe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a61a2b25-0b90-4074-81c2-f80b6f0e26c7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    f\"./lang_adapters/{experiment}/model\",\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=15,\n",
    "    warmup_steps=0,\n",
    "    # lr_scheduler_type='cosine_with_restarts',\n",
    "    # gradient_accumulation_steps=4,\n",
    "    eval_accumulation_steps=16,\n",
    "    # gradient_checkpointing=True,\n",
    "    # predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=5,\n",
    "    # eval_steps=5,\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"bleu\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    #optimizers=(optimizer, lr_scheduler),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a361ae7-3f1f-413a-bda9-1e6fe6ee4899",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akufeldt/miniconda3/envs/nlp_env/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 9818\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2310\n",
      "  Number of trainable parameters = 4757760\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1387' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1387/2310 1:15:42 < 50:26, 0.30 it/s, Epoch 9/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.956600</td>\n",
       "      <td>10.893058</td>\n",
       "      <td>4.102800</td>\n",
       "      <td>0.994200</td>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10.587800</td>\n",
       "      <td>10.351295</td>\n",
       "      <td>4.100800</td>\n",
       "      <td>0.993400</td>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.843600</td>\n",
       "      <td>9.646740</td>\n",
       "      <td>3.923600</td>\n",
       "      <td>0.990800</td>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.180400</td>\n",
       "      <td>8.459710</td>\n",
       "      <td>2.943200</td>\n",
       "      <td>0.991400</td>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7.717900</td>\n",
       "      <td>7.466567</td>\n",
       "      <td>1.029900</td>\n",
       "      <td>1.337300</td>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.235700</td>\n",
       "      <td>7.052766</td>\n",
       "      <td>0.646200</td>\n",
       "      <td>1.791400</td>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7.011100</td>\n",
       "      <td>6.922141</td>\n",
       "      <td>0.581800</td>\n",
       "      <td>1.994300</td>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7.004700</td>\n",
       "      <td>6.872288</td>\n",
       "      <td>0.572100</td>\n",
       "      <td>2.026700</td>\n",
       "      <td>256.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 01:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1113\n",
      "  Batch size = 16\n",
      "/tmp/ipykernel_2549/3289696467.py:37: UserWarning: preds: Ssa\n",
      ")\n",
      "  warnings.warn(f\"preds: {decoded_preds[0]}\\n)\")\n",
      "/tmp/ipykernel_2549/3289696467.py:38: UserWarning: labels: Amsa\n",
      ")\n",
      "  warnings.warn(f\"labels: {decoded_labels[0]}\\n)\")\n",
      "Saving model checkpoint to ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-154\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-154/enc_en/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-154/enc_en/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-154/enc_en/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-154/enc_en/pytorch_model_head.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-154/dec_ha/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-154/dec_ha/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-154/dec_ha/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-154/dec_ha/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-154/tokenizer_config.json\n",
      "Special tokens file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-154/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1113\n",
      "  Batch size = 16\n",
      "/tmp/ipykernel_2549/3289696467.py:37: UserWarning: preds: Ssa\n",
      ")\n",
      "  warnings.warn(f\"preds: {decoded_preds[0]}\\n)\")\n",
      "/tmp/ipykernel_2549/3289696467.py:38: UserWarning: labels: Amsa\n",
      ")\n",
      "  warnings.warn(f\"labels: {decoded_labels[0]}\\n)\")\n",
      "Saving model checkpoint to ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-308\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-308/enc_en/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-308/enc_en/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-308/enc_en/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-308/enc_en/pytorch_model_head.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-308/dec_ha/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-308/dec_ha/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-308/dec_ha/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-308/dec_ha/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-308/tokenizer_config.json\n",
      "Special tokens file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-308/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1113\n",
      "  Batch size = 16\n",
      "/tmp/ipykernel_2549/3289696467.py:37: UserWarning: preds: sa\n",
      ")\n",
      "  warnings.warn(f\"preds: {decoded_preds[0]}\\n)\")\n",
      "/tmp/ipykernel_2549/3289696467.py:38: UserWarning: labels: Amsa\n",
      ")\n",
      "  warnings.warn(f\"labels: {decoded_labels[0]}\\n)\")\n",
      "Saving model checkpoint to ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-462\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-462/enc_en/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-462/enc_en/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-462/enc_en/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-462/enc_en/pytorch_model_head.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-462/dec_ha/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-462/dec_ha/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-462/dec_ha/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-462/dec_ha/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-462/tokenizer_config.json\n",
      "Special tokens file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-462/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1113\n",
      "  Batch size = 16\n",
      "/tmp/ipykernel_2549/3289696467.py:37: UserWarning: preds: sa а а\n",
      ")\n",
      "  warnings.warn(f\"preds: {decoded_preds[0]}\\n)\")\n",
      "/tmp/ipykernel_2549/3289696467.py:38: UserWarning: labels: Amsa\n",
      ")\n",
      "  warnings.warn(f\"labels: {decoded_labels[0]}\\n)\")\n",
      "Saving model checkpoint to ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-616\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-616/enc_en/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-616/enc_en/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-616/enc_en/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-616/enc_en/pytorch_model_head.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-616/dec_ha/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-616/dec_ha/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-616/dec_ha/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-616/dec_ha/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-616/tokenizer_config.json\n",
      "Special tokens file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-616/special_tokens_map.json\n",
      "Deleting older checkpoint [lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-308] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1113\n",
      "  Batch size = 16\n",
      "/tmp/ipykernel_2549/3289696467.py:37: UserWarning: preds: Ssaäääammoùammoùammoùammoùammoùammoùammoùammoùammoùammoùammoùammoù batzu batzu batzu batzu batzu batzu\n",
      ")\n",
      "  warnings.warn(f\"preds: {decoded_preds[0]}\\n)\")\n",
      "/tmp/ipykernel_2549/3289696467.py:38: UserWarning: labels: Amsa\n",
      ")\n",
      "  warnings.warn(f\"labels: {decoded_labels[0]}\\n)\")\n",
      "Saving model checkpoint to ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-770\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-770/enc_en/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-770/enc_en/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-770/enc_en/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-770/enc_en/pytorch_model_head.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-770/dec_ha/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-770/dec_ha/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-770/dec_ha/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-770/dec_ha/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-770/tokenizer_config.json\n",
      "Special tokens file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-770/special_tokens_map.json\n",
      "Deleting older checkpoint [lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-462] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1113\n",
      "  Batch size = 16\n",
      "/tmp/ipykernel_2549/3289696467.py:37: UserWarning: preds: Ssaammoùammoùammoùammoùammoùammoùammoùammoùammoùammoùammoùammoùammoùammoù batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu batzu\n",
      ")\n",
      "  warnings.warn(f\"preds: {decoded_preds[0]}\\n)\")\n",
      "/tmp/ipykernel_2549/3289696467.py:38: UserWarning: labels: Amsa\n",
      ")\n",
      "  warnings.warn(f\"labels: {decoded_labels[0]}\\n)\")\n",
      "Saving model checkpoint to ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-924\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-924/enc_en/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-924/enc_en/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-924/enc_en/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-924/enc_en/pytorch_model_head.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-924/dec_ha/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-924/dec_ha/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-924/dec_ha/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-924/dec_ha/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-924/tokenizer_config.json\n",
      "Special tokens file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-924/special_tokens_map.json\n",
      "Deleting older checkpoint [lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-616] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1113\n",
      "  Batch size = 16\n",
      "/tmp/ipykernel_2549/3289696467.py:37: UserWarning: preds: Ssaammoùammoùammoùammoù ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ\n",
      ")\n",
      "  warnings.warn(f\"preds: {decoded_preds[0]}\\n)\")\n",
      "/tmp/ipykernel_2549/3289696467.py:38: UserWarning: labels: Amsa\n",
      ")\n",
      "  warnings.warn(f\"labels: {decoded_labels[0]}\\n)\")\n",
      "Saving model checkpoint to ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1078\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1078/enc_en/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1078/enc_en/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1078/enc_en/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1078/enc_en/pytorch_model_head.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1078/dec_ha/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1078/dec_ha/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1078/dec_ha/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1078/dec_ha/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1078/tokenizer_config.json\n",
      "Special tokens file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1078/special_tokens_map.json\n",
      "Deleting older checkpoint [lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-770] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1113\n",
      "  Batch size = 16\n",
      "/tmp/ipykernel_2549/3289696467.py:37: UserWarning: preds: Ssa ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ ਅੰਮ੍ਰਿਤਸਰ\n",
      ")\n",
      "  warnings.warn(f\"preds: {decoded_preds[0]}\\n)\")\n",
      "/tmp/ipykernel_2549/3289696467.py:38: UserWarning: labels: Amsa\n",
      ")\n",
      "  warnings.warn(f\"labels: {decoded_labels[0]}\\n)\")\n",
      "Saving model checkpoint to ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1232\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1232/enc_en/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1232/enc_en/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1232/enc_en/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1232/enc_en/pytorch_model_head.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1232/dec_ha/adapter_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1232/dec_ha/pytorch_adapter.bin\n",
      "Configuration saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1232/dec_ha/head_config.json\n",
      "Module weights saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1232/dec_ha/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1232/tokenizer_config.json\n",
      "Special tokens file saved in ./lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-1232/special_tokens_map.json\n",
      "Deleting older checkpoint [lang_adapters/en-ha_adapters_new_wd01_lr5e-6_e15/model/checkpoint-924] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1113\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27388ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "if not os.path.exists(f'./base_model/{experiment}'):\n",
    "    os.mkdir(f'./base_model/{experiment}')\n",
    "    \n",
    "trainer.save_model(f\"./base_model/{experiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval finetuned model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a928793b-3fa2-45ab-aec7-3b0634a32869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance\n",
    "src_lang = 'en'\n",
    "tgt_lang = 'ha'\n",
    "tokenizer.src_lang = \"en\"\n",
    "tokenizer.tgt_lang = \"ha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3692c-9109-4d77-92ef-80ae133e1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = M2M100ForConditionalGeneration.from_pretrained(f\"./base_model/{experiment}\")\n",
    "# model = torch.nn.DataParallel(model, device_ids=[2, 3, 4])\n",
    "model = model.to(device)\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(f\"./base_model/{experiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f4e6d2-f884-4a9c-a4ff-c1fa70b55da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_outputs = trainer.evaluate(tokenized_dataset['test']) #, forced_bos_token_id=tokenizer.get_lang_id(\"ha\")\n",
    "#test_output_texts = tokenizer.batch_decode(torch.LongTensor(test_outputs.predictions), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024e8a5-7972-4c42-a4e1-dbe23c20b7f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
