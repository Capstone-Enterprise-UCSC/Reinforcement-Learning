{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3551c529-fcb2-458d-8e5c-4544876eba0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phonnego/miniconda3/envs/nlp_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Softmax\n",
    "\n",
    "from typing import List, Optional, Tuple, Union, Dict, Any\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict, load_metric, load_from_disk, concatenate_datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, EarlyStoppingCallback\n",
    "from transformers import PreTrainedModel, TrainingArguments, Trainer\n",
    "#from transformers.adapters import AdapterTrainer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "_numpy_rng = np.random.default_rng(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./monolingual-data/hau', 'r') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lokacin da za ku buga bugun bugawa, za a tambayi ku ko kuna son wani yanki mai zaman kansa kyauta ko wani yanki mai suna.\n",
      "\n",
      "Sannan Ahmad ibn Hanbal ya ce: da za’a karanta wannan isandi kan mahaukaci da take ya warke daga cutar hauka.\n",
      "\n",
      "Labarin \"mummunan labari\" na tsawon lokaci game da yara kimanin 40 a cikin ciki ya dade daɗewa.\n",
      "\n",
      "Muna ɗaure shi da jaka kuma rataya shi a kalla a rana a kan akwati mai dacewa.\n",
      "\n",
      "Yana da shawara cewa an yi amfani da takin gargajiya ko ma'adinai don amfani da shafin yayin digging.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./monolingual-data/hau', 'r') as file:\n",
    "    for i in range(5):\n",
    "        data1 = file.readline()\n",
    "        print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lokacin da za ku buga bugun bugawa, za a tambayi ku ko kuna son wani yanki mai zaman kansa kyauta ko wani yanki mai suna.',\n",
       " 'Sannan Ahmad ibn Hanbal ya ce: da za’a karanta wannan isandi kan mahaukaci da take ya warke daga cutar hauka.',\n",
       " 'Labarin \"mummunan labari\" na tsawon lokaci game da yara kimanin 40 a cikin ciki ya dade daɗewa.',\n",
       " 'Muna ɗaure shi da jaka kuma rataya shi a kalla a rana a kan akwati mai dacewa.',\n",
       " \"Yana da shawara cewa an yi amfani da takin gargajiya ko ma'adinai don amfani da shafin yayin digging.\",\n",
       " 'Yana da mahimmanci kada kuyi canjin saurin sauƙi, amma tsabtace hanyoyi, gano bakan gizo.',\n",
       " 'Jim kadan da bayyana wannan sako ne sai shugaba Trump ya bayyana shi a shafinsa na twiter.',\n",
       " \"Laser yankan tube kayan ne wani sabon tsari wanda ya zama mafi rare a 'yan shekarun nan.\",\n",
       " 'Ya ce Sheriff na tafe ne da tawagar kasaitattun motoci guda tara a jere.',\n",
       " 'Kadan daga cikin abin da yasa hakan shi ne: hikimar sarrafa hannu da aiki da shi tana komawa ga kafafuwan nasu ne, saboda basu da hannu.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3520671"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ha': sentences})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./monolingual-data/ha_monolingual.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./monolingual-data/ha_monolingual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lokacin da za ku buga bugun bugawa, za a tamba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sannan Ahmad ibn Hanbal ya ce: da za’a karanta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Labarin \"mummunan labari\" na tsawon lokaci gam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muna ɗaure shi da jaka kuma rataya shi a kalla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yana da shawara cewa an yi amfani da takin gar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ha\n",
       "0  Lokacin da za ku buga bugun bugawa, za a tamba...\n",
       "1  Sannan Ahmad ibn Hanbal ya ce: da za’a karanta...\n",
       "2  Labarin \"mummunan labari\" na tsawon lokaci gam...\n",
       "3  Muna ɗaure shi da jaka kuma rataya shi a kalla...\n",
       "4  Yana da shawara cewa an yi amfani da takin gar..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3520671"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv(csv_file):\n",
    "    # Clean the data\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "    # drop rows with first column value 'English'\n",
    "    df = df[df.iloc[:,0] != 'English']\n",
    "    # # drop rows with just '.' or ',' or '?' in first column\n",
    "    df = df[df.iloc[:,0] != '.']\n",
    "    df = df[df.iloc[:,0] != ',']\n",
    "    df = df[df.iloc[:,0] != '?']\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = clean_csv('./monolingual-data/ha_monolingual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = Dataset.from_dict({'ha': data_cleaned['ha']})\n",
    "small_dataset = all_dataset.shuffle(seed=seed).select(range(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({'complete': all_dataset, 'small': small_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    complete: Dataset({\n",
       "        features: ['ha'],\n",
       "        num_rows: 3372487\n",
       "    })\n",
       "    small: Dataset({\n",
       "        features: ['ha'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 3373/3373 [00:03<00:00, 956.77ba/s] \n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.60s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 100/100 [00:01<00:00, 62.21ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n",
      "README.md: 100%|██████████| 398/398 [00:00<00:00, 55.3kB/s]\n"
     ]
    }
   ],
   "source": [
    "dataset.push_to_hub(\"monolingual-ha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.to_csv('./monolingual-data/ha_cleaned_monolingual.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = data_cleaned['ha'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_lengths = [len(sentence.split()) for sentence in sentences]\n",
    "\n",
    "longest_sentence = sent[sentence_lengths.index(max(sentence_lengths))]\n",
    "shortest_sentence = sent[sentence_lengths.index(min(sentence_lengths))]\n",
    "\n",
    "average_sentence_length = sum(sentence_lengths) / len(sentence_lengths)\n",
    "\n",
    "print(f\"Longest Sentence: {longest_sentence}\", len(longest_sentence.split()))\n",
    "print(f\"Shortest Sentence: {shortest_sentence}\", len(shortest_sentence.split()))\n",
    "print(f\"Average Sentence Length: {average_sentence_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
